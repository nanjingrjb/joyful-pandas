{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>第二章 pandas基础</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#采用高级容器\n",
    "\n",
    "from collections import namedtuple as np\n",
    "pt=np(\"mypo\",[\"x\",\"y\"])\n",
    "p=pt(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rjb 42 123\n",
      "wj 40 125\n"
     ]
    }
   ],
   "source": [
    "info=np(\"info\",[\"name\",\"age\",\"phone\"])\n",
    "lst=[]\n",
    "rjb=info(\"rjb\",42,\"123\")\n",
    "wj=info(\"wj\",40,\"125\")\n",
    "lst.append(rjb)\n",
    "lst.append(wj)\n",
    "\n",
    "for i in lst:\n",
    "    print(i.name,i.age,i.phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.x\n",
    "isinstance(p,tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome,rjq\n",
      "p is instanceof list?\n",
      "answer is 1 .\n",
      "['1', '2']\n",
      "rjq\n",
      "rjq\n"
     ]
    }
   ],
   "source": [
    "#类的定义与继承\n",
    "class mylist(list):\n",
    "    def __init__(self,name=\"rjb\"):\n",
    "        self.name=name\n",
    "        print(\"welcome,%s\"%self.name)\n",
    "    \n",
    "\n",
    "issubclass(mylist,list)\n",
    "p=mylist(\"rjq\")\n",
    "print(\"p is instanceof list?\\nanswer is %d .\"%isinstance(p,list))\n",
    "p.append(\"1\")\n",
    "p.append(\"2\")\n",
    "print(p)\n",
    "\n",
    "for i in p:\n",
    "    print(p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import webbrowser\r\n",
      "def myos():\r\n",
      "    os.system(\"/bin/pwd\")\r\n",
      "    os.system(\"bash /sdcard/111py/py/hi.sh\")\r\n",
      "    os.system(\"bash /sdcard/111py/py/findsrc.sh\")\r\n",
      "    webbrowser.open('http://www.python.org')\r\n",
      "\r\n",
      "\r\n",
      "myos()\r\n"
     ]
    }
   ],
   "source": [
    "cat /sdcard/111py/py/myos.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34m__pycache__\u001b[m/   \u001b[0;0mhellow.py\u001b[m      \u001b[0;0mname.py\u001b[m        \u001b[0;0mreadf.py\u001b[m       \u001b[0;0mtestreg.py\u001b[m\r\n",
      "\u001b[0;0mfilein.py\u001b[m      \u001b[0;0mhi.sh\u001b[m          \u001b[0;0mname.xlsx\u001b[m      \u001b[0;0mregfind.py\u001b[m     \u001b[0;0mweight.py\u001b[m\r\n",
      "\u001b[0;0mfileobj.py\u001b[m     \u001b[1;34mjoyful-pandas\u001b[m/ \u001b[0;0mnum.txt\u001b[m        \u001b[0;0msys.py\u001b[m\r\n",
      "\u001b[0;0mfindsrc.sh\u001b[m     \u001b[0;0mmyos.py\u001b[m        \u001b[0;0mpandas.ipynb\u001b[m   \u001b[0;0mtestpy.ipynb\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "ls /sdcard/111py/py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/emulated/0/BaiduNetDisk\n",
      "this is a test called by python. if you say it,you get it.\n",
      "there is no yu.txt\n",
      "no src file in /mnt/e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: /mnt/e: No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/user/0/ru.iiec.pydroid3/files/mybrowser\", line 23, in <module>\n",
      "    sock.connect(os.environ['PYDROID_RPC'])\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path\n",
    "home=\"/sdcard/111py/py\"\n",
    "sys.path.append(home)\n",
    "#导入自定义模块my\n",
    "from myos import myos\n",
    "myos()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/storage/emulated/0/111py/py/joyful-pandas/notebook',\n",
       " '/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python39.zip',\n",
       " '/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9',\n",
       " '/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/data/user/0/ru.iiec.pydroid3/app_HOME/.local/lib/python3.9/site-packages',\n",
       " '/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9/site-packages',\n",
       " '/sdcard/111py/py']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/storage/emulated/0/111py/py/joyful-pandas/notebook'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2) [1, 2] (1, 2)\n"
     ]
    }
   ],
   "source": [
    "#元组和列表的转换\n",
    "a=(1,2)\n",
    "b=list(a)\n",
    "c=tuple(b)\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用字典关键字的唯一性，天然去重\n",
    "def uniq_dict(m):\n",
    "    t=dict()\n",
    "    for i in m:\n",
    "        t[i]=1\n",
    "    return t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "end\n",
      "['c', 'a', 'b'] {'c', 'aaa', 'bb'} ab\n"
     ]
    }
   ],
   "source": [
    "#删除列表中的重复元素\n",
    "def uniqlist(m):\n",
    "    plist=[]\n",
    "    #去重操作\n",
    "    t=list(set(m))\n",
    "    for i in t:\n",
    "        plist.append(uniqalp(i))\n",
    "    return plist\n",
    "def uniqalp(stra):\n",
    "    if isinstance(stra,str):\n",
    "        pset=set(stra)\n",
    "        m=str()\n",
    "        for i in pset:\n",
    "            m+=''.join(i)\n",
    "    else:\n",
    "        print('str must be input.')\n",
    "        return ''\n",
    "    return m\n",
    "def nullfun():\n",
    "    print(\"start\")\n",
    "    pass\n",
    "    print(\"end\")\n",
    "\n",
    "nullfun()\n",
    "m=['a'*3,'b'*2,'c','a'*3,'b'*2,'c']\n",
    "print(uniqlist(m),set(m),uniqalp('a'*2+'b'*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['aaa', 'bb', 'c']) <class 'dict_keys'>\n",
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "t=uniq_dict(m)\n",
    "#字典的关键字并非列表，需强制转化\n",
    "print(t,type(t))\n",
    "p=list(t)\n",
    "m=[]\n",
    "for i in p:\n",
    "    m+=uniqalp(i)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 45, 2: 'gh', 3: 'op'}\n",
      "{45: 1, 'gh': 2, 'op': 3}\n"
     ]
    }
   ],
   "source": [
    "#字典推导\n",
    "a={1:45,2:\"gh\",3:\"op\"}\n",
    "print(a)\n",
    "b={v:k for k,v in a.items()}\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 4, 36}\n"
     ]
    }
   ],
   "source": [
    "#集合推导式\n",
    "myset={x*x for x in [1,2,-1,-2,6]}\n",
    "print(myset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 9)\n"
     ]
    }
   ],
   "source": [
    "#推导元组\n",
    "mytuple=(x*x for x in [1,2,3])\n",
    "m=tuple(mytuple)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4), (2, 4), (3, 4)]\n"
     ]
    }
   ],
   "source": [
    "#多个条件符合成条件列表\n",
    "t=[(x,y) for x in [1,2,3] for y in\n",
    "   [1,3,4] if x!=y and y%2==0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 8, 9, 10, 11, 13, 15, 19, 20, 22, 23, 25, 29, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 50, 51, 52, 53, 55, 58, 59, 80, 81, 82, 83, 85, 88, 89, 92, 93, 94, 95, 99] 47\n"
     ]
    }
   ],
   "source": [
    "#100以内，不含6，不是6的倍数的整数\n",
    "def myint(x,p):\n",
    "    if int(x/10)!=p and x%10!=p and x%p!=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "m=[x for x in range(1,100)  if myint(x,6) and myint(x,7)]\n",
    "print(m,len(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 9, 25]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#range start stop step ,index<stop\n",
    "alist=[i**2 for i in range(1,6,2)]\n",
    "alist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "1\n",
      "4\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#列表式推导\n",
    "vec=[[1 ,2, 3],[4 ,5 ,6],[7, 8 ,9]]\n",
    "print(vec)\n",
    "v=[col for row in vec for col in row]\n",
    "print(v)\n",
    "#对vec内单个元素进行解析，abc分别为123\n",
    "for a,b,c in vec:\n",
    "    print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2, 2: 3, 3: 4} <class 'dict'> dict_items([(1, 2), (2, 3), (3, 4)])\n",
      "{1: 4, 2: 6, 3: 8}\n",
      "[]\n",
      "()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "#lambda函数结合map遍历，filter过滤，reduce累加\n",
    "#的处理\n",
    "s1={1:2,2:3,3:4}\n",
    "print(s1,type(s1),s1.items())\n",
    "t=s1.items()\n",
    "mydic=map(lambda x:(x[0],2*x[1]),t)\n",
    "print(dict(mydic))\n",
    "print(list(mydic))\n",
    "print(tuple(mydic))\n",
    "print(set(mydic))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, -7]\n"
     ]
    }
   ],
   "source": [
    "s2=[1,2,6,-7,5.1]\n",
    "t=filter(lambda x:x<2,s2)\n",
    "print(list(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.1\n"
     ]
    }
   ],
   "source": [
    "import functools as ft\n",
    "m=ft.reduce(lambda x,y:x-y,s2)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在开始学习前，请保证`pandas`的版本号不低于如下所示的版本，否则请务必升级！请确认已经安装了`xlrd, xlwt, openpyxl`这三个包，其中`xlrd`版本不得高于`2.0.0`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.3'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add=lambda x,y:x+y\n",
    "y=add(1,2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 22, 23, 24, 25, 26)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1=(1,2,3,4,5,6)   \n",
    "y=10\n",
    "t=map(lambda x:x+2*y,s1)      \n",
    "tuple(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 22, 23, 24, 25, 26]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m=(21, 22, 23, 24, 25, 26)\n",
    "m=list(m)\n",
    "print(m)\n",
    "n=filter(lambda x:x>21 and x%2==1,m)\n",
    "p=set(m)-set(n)\n",
    "t=list(p)\n",
    "print(m.sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 1, 0, -8]\n"
     ]
    }
   ],
   "source": [
    "s3=[1,0,-8,6,2]\n",
    "s3.sort(reverse=True)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8, 0, 1, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "s3.sort(reverse=False)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list.sort?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typea=lambda p:p()\n",
    "type(typea)\n",
    "a=typea(list)\n",
    "for i in range(2):\n",
    "    a.append(i)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function <listcomp>.<lambda> at 0x729cb38a60>, <function <listcomp>.<lambda> at 0x729cb38c10>, <function <listcomp>.<lambda> at 0x729cb38ca0>, <function <listcomp>.<lambda> at 0x729cb38d30>, <function <listcomp>.<lambda> at 0x729cb38dc0>, <function <listcomp>.<lambda> at 0x729cb38e50>]\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#  给出一个值 x ，分别计算 x 与 0~5 之间各个数的和\n",
    "res=[lambda x,i=i:x+i for i in range (6)]\n",
    "print(res)       #得到返回 x+i 函数的五个地址\n",
    "\n",
    "for f in res:    #循环遍历每个地址\n",
    "    print(f(2))  #对每个遍历到的函数 传递参数 x=2\n",
    "#2 3 4 5 6 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=lambda x,y:x+y\n",
    "a=1\n",
    "b=2\n",
    "c=w(a,b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch(x,y):\n",
    "    return (y,x)\n",
    "w=lambda x,y:(y,x)#switch(x,y)\n",
    "a=1\n",
    "b=2\n",
    "(a,b)=w(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old is: /storage/emulated/0/111py/py/joyful-pandas/notebook\n",
      "exist tmp1.remove it.\n",
      "./电力系统分析（saadat着，王葵译）.xdf\n",
      "./pandas-1.3.3.tar.gz\n",
      "./0922.scd\n",
      "./1_专业检测2.scd\n",
      "./.tdck\n",
      "./积成，动稳破坏振荡，BC故障，纵差选B，跳B，80ms后三跳.rar\n",
      "./1_积成，动稳破坏振荡，BC故障，纵差选B，跳B，80ms后三跳.rar\n",
      "./动动图片/20140131 (23).jpg\n",
      "./动动图片/IMG_20140809_122206.jpg\n",
      "./手机备份/IMG_20160208_135415.jpg\n",
      "./来自：Che2-TL00/DCIM/Camera/IMG_20170329_180600.jpg\n",
      "./wjzp/IMG_20150219_115433.jpg\n",
      "./wjzp/IMG_20150221_145618.jpg\n",
      "./wjzp/20131122 (16).JPG\n",
      "./小动视频/VID_20140830_114922.mp4\n",
      "./小动视频/19165418051522e2adf49012.mp4\n",
      "./1-工作相关/ieslab/开普new_EDPSim_Release.rar\n",
      "./BaiduYunKernel/.accelerate/.accelerate.m3u8bn\n",
      "./BaiduYunKernel/.accelerate/sdkconfig\n",
      "./BaiduYunKernel/.accelerate/英语世界/【Michael钱儿频道】Word World 单词世界（1-3季）/第1季/105.avi/105.avi.m3u8bn\n",
      "./BaiduYunKernel/.accelerate/英语世界/【Michael钱儿频道】Word World 单词世界（1-3季）/第1季/105.avi/sdkconfig\n",
      "./BaiduYunKernel/.accelerate/英语世界/【Michael钱儿频道】Word World 单词世界（1-3季）/第1季/105.avi/105.avi.m3u8\n",
      "./百度网盘收件箱/.thumbnails/1115669049_header.png\n",
      "./百度网盘收件箱/.thumbnails/678339333_header.png\n",
      "./私人资料/动动图片/20140213 (2).JPG\n",
      "./私人资料/动动图片/20131122 (16).JPG\n",
      "./私人资料/动动图片/20140117 (1).jpg\n",
      "./私人资料/动动图片/IMG_20140330_110943.jpg\n",
      "./私人资料/动动图片/20140131 (5).JPG\n",
      "./私人资料/动动图片/20140407.jpg\n",
      "./私人资料/动动图片/IMG_20140816_115718.jpg\n",
      "./私人资料/动动图片/IMG_20140501_102957.jpg\n",
      "./私人资料/动动图片/IMG_20140525_110715.jpg\n",
      "./私人资料/动动图片/IMG_20140802_101807.jpg\n",
      "./私人资料/手机备份/IMG_20160710_104939.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#获取当前路径\n",
    "print(\"old is:\",os.getcwd())\n",
    "#print(os.getenv(\"PATH\"))\n",
    "os.chdir(\"/sdcard/BaiduNetDisk\")\n",
    "#print(\"now dir is:\",os.getcwd(),os.listdir())\n",
    "\n",
    "if \"tmp1\" in os.listdir():\n",
    "    print(\"exist tmp1.remove it.\")\n",
    "    os.rmdir(\"tmp1\")\n",
    "else:\n",
    "    print(\"no tmp1.\")\n",
    "os.mkdir(\"tmp1\")\n",
    "\n",
    "mydir=list(os.walk(\"./\"))\n",
    "#print(mydir,len(mydir))\n",
    "for root,dirs,files in os.walk(\"./\"):\n",
    "    for file in files:\n",
    "        fpath=os.path.join(root,file)\n",
    "        print(fpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_get_sep',\n",
       " '_joinrealpath',\n",
       " '_varprog',\n",
       " '_varprogb',\n",
       " 'abspath',\n",
       " 'altsep',\n",
       " 'basename',\n",
       " 'commonpath',\n",
       " 'commonprefix',\n",
       " 'curdir',\n",
       " 'defpath',\n",
       " 'devnull',\n",
       " 'dirname',\n",
       " 'exists',\n",
       " 'expanduser',\n",
       " 'expandvars',\n",
       " 'extsep',\n",
       " 'genericpath',\n",
       " 'getatime',\n",
       " 'getctime',\n",
       " 'getmtime',\n",
       " 'getsize',\n",
       " 'isabs',\n",
       " 'isdir',\n",
       " 'isfile',\n",
       " 'islink',\n",
       " 'ismount',\n",
       " 'join',\n",
       " 'lexists',\n",
       " 'normcase',\n",
       " 'normpath',\n",
       " 'os',\n",
       " 'pardir',\n",
       " 'pathsep',\n",
       " 'realpath',\n",
       " 'relpath',\n",
       " 'samefile',\n",
       " 'sameopenfile',\n",
       " 'samestat',\n",
       " 'sep',\n",
       " 'split',\n",
       " 'splitdrive',\n",
       " 'splitext',\n",
       " 'stat',\n",
       " 'supports_unicode_filenames',\n",
       " 'sys']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(os.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in module sys:\n",
      "\n",
      "NAME\n",
      "    sys\n",
      "\n",
      "MODULE REFERENCE\n",
      "    https://docs.python.org/3.9/library/sys\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    This module provides access to some objects used or maintained by the\n",
      "    interpreter and to functions that interact strongly with the interpreter.\n",
      "    \n",
      "    Dynamic objects:\n",
      "    \n",
      "    argv -- command line arguments; argv[0] is the script pathname if known\n",
      "    path -- module search path; path[0] is the script directory, else ''\n",
      "    modules -- dictionary of loaded modules\n",
      "    \n",
      "    displayhook -- called to show results in an interactive session\n",
      "    excepthook -- called to handle any uncaught exception other than SystemExit\n",
      "      To customize printing in an interactive session or to install a custom\n",
      "      top-level exception handler, assign other functions to replace these.\n",
      "    \n",
      "    stdin -- standard input file object; used by input()\n",
      "    stdout -- standard output file object; used by print()\n",
      "    stderr -- standard error object; used for error messages\n",
      "      By assigning other file objects (or objects that behave like files)\n",
      "      to these, it is possible to redirect all of the interpreter's I/O.\n",
      "    \n",
      "    last_type -- type of last uncaught exception\n",
      "    last_value -- value of last uncaught exception\n",
      "    last_traceback -- traceback of last uncaught exception\n",
      "      These three are only available in an interactive session after a\n",
      "      traceback has been printed.\n",
      "    \n",
      "    Static objects:\n",
      "    \n",
      "    builtin_module_names -- tuple of module names built into this interpreter\n",
      "    copyright -- copyright notice pertaining to this interpreter\n",
      "    exec_prefix -- prefix used to find the machine-specific Python library\n",
      "    executable -- absolute path of the executable binary of the Python interpreter\n",
      "    float_info -- a named tuple with information about the float implementation.\n",
      "    float_repr_style -- string indicating the style of repr() output for floats\n",
      "    hash_info -- a named tuple with information about the hash algorithm.\n",
      "    hexversion -- version information encoded as a single integer\n",
      "    implementation -- Python implementation information.\n",
      "    int_info -- a named tuple with information about the int implementation.\n",
      "    maxsize -- the largest supported length of containers.\n",
      "    maxunicode -- the value of the largest Unicode code point\n",
      "    platform -- platform identifier\n",
      "    prefix -- prefix used to find the Python library\n",
      "    thread_info -- a named tuple with information about the thread implementation.\n",
      "    version -- the version of this interpreter as a string\n",
      "    version_info -- version information as a named tuple\n",
      "    __stdin__ -- the original stdin; don't touch!\n",
      "    __stdout__ -- the original stdout; don't touch!\n",
      "    __stderr__ -- the original stderr; don't touch!\n",
      "    __displayhook__ -- the original displayhook; don't touch!\n",
      "    __excepthook__ -- the original excepthook; don't touch!\n",
      "    \n",
      "    Functions:\n",
      "    \n",
      "    displayhook() -- print an object to the screen, and save it in builtins._\n",
      "    excepthook() -- print an exception and its traceback to sys.stderr\n",
      "    exc_info() -- return thread-safe information about the current exception\n",
      "    exit() -- exit the interpreter by raising SystemExit\n",
      "    getdlopenflags() -- returns flags to be used for dlopen() calls\n",
      "    getprofile() -- get the global profiling function\n",
      "    getrefcount() -- return the reference count for an object (plus one :-)\n",
      "    getrecursionlimit() -- return the max recursion depth for the interpreter\n",
      "    getsizeof() -- return the size of an object in bytes\n",
      "    gettrace() -- get the global debug tracing function\n",
      "    setdlopenflags() -- set the flags to be used for dlopen() calls\n",
      "    setprofile() -- set the global profiling function\n",
      "    setrecursionlimit() -- set the max recursion depth for the interpreter\n",
      "    settrace() -- set the global debug tracing function\n",
      "\n",
      "FUNCTIONS\n",
      "    __breakpointhook__ = breakpointhook(...)\n",
      "        breakpointhook(*args, **kws)\n",
      "        \n",
      "        This hook function is called by built-in breakpoint().\n",
      "    \n",
      "    __displayhook__ = displayhook(object, /)\n",
      "        Print an object to sys.stdout and also save it in builtins._\n",
      "    \n",
      "    __excepthook__ = excepthook(exctype, value, traceback, /)\n",
      "        Handle an exception by displaying it with a traceback on sys.stderr.\n",
      "    \n",
      "    __unraisablehook__ = unraisablehook(unraisable, /)\n",
      "        Handle an unraisable exception.\n",
      "        \n",
      "        The unraisable argument has the following attributes:\n",
      "        \n",
      "        * exc_type: Exception type.\n",
      "        * exc_value: Exception value, can be None.\n",
      "        * exc_traceback: Exception traceback, can be None.\n",
      "        * err_msg: Error message, can be None.\n",
      "        * object: Object causing the exception, can be None.\n",
      "    \n",
      "    addaudithook(hook)\n",
      "        Adds a new audit hook callback.\n",
      "    \n",
      "    audit(...)\n",
      "        audit(event, *args)\n",
      "        \n",
      "        Passes the event to any audit hooks that are attached.\n",
      "    \n",
      "    call_tracing(func, args, /)\n",
      "        Call func(*args), while tracing is enabled.\n",
      "        \n",
      "        The tracing state is saved, and restored afterwards.  This is intended\n",
      "        to be called from a debugger from a checkpoint, to recursively debug\n",
      "        some other code.\n",
      "    \n",
      "    exc_info()\n",
      "        Return current exception information: (type, value, traceback).\n",
      "        \n",
      "        Return information about the most recent exception caught by an except\n",
      "        clause in the current stack frame or in an older stack frame.\n",
      "    \n",
      "    exit(status=None, /)\n",
      "        Exit the interpreter by raising SystemExit(status).\n",
      "        \n",
      "        If the status is omitted or None, it defaults to zero (i.e., success).\n",
      "        If the status is an integer, it will be used as the system exit status.\n",
      "        If it is another kind of object, it will be printed and the system\n",
      "        exit status will be one (i.e., failure).\n",
      "    \n",
      "    get_asyncgen_hooks()\n",
      "        Return the installed asynchronous generators hooks.\n",
      "        \n",
      "        This returns a namedtuple of the form (firstiter, finalizer).\n",
      "    \n",
      "    get_coroutine_origin_tracking_depth()\n",
      "        Check status of origin tracking for coroutine objects in this thread.\n",
      "    \n",
      "    getallocatedblocks()\n",
      "        Return the number of memory blocks currently allocated.\n",
      "    \n",
      "    getandroidapilevel()\n",
      "        Return the build time API version of Android as an integer.\n",
      "    \n",
      "    getdefaultencoding()\n",
      "        Return the current default encoding used by the Unicode implementation.\n",
      "    \n",
      "    getdlopenflags()\n",
      "        Return the current value of the flags that are used for dlopen calls.\n",
      "        \n",
      "        The flag constants are defined in the os module.\n",
      "    \n",
      "    getfilesystemencodeerrors()\n",
      "        Return the error mode used Unicode to OS filename conversion.\n",
      "    \n",
      "    getfilesystemencoding()\n",
      "        Return the encoding used to convert Unicode filenames to OS filenames.\n",
      "    \n",
      "    getprofile()\n",
      "        Return the profiling function set with sys.setprofile.\n",
      "        \n",
      "        See the profiler chapter in the library manual.\n",
      "    \n",
      "    getrecursionlimit()\n",
      "        Return the current value of the recursion limit.\n",
      "        \n",
      "        The recursion limit is the maximum depth of the Python interpreter\n",
      "        stack.  This limit prevents infinite recursion from causing an overflow\n",
      "        of the C stack and crashing Python.\n",
      "    \n",
      "    getrefcount(object, /)\n",
      "        Return the reference count of object.\n",
      "        \n",
      "        The count returned is generally one higher than you might expect,\n",
      "        because it includes the (temporary) reference as an argument to\n",
      "        getrefcount().\n",
      "    \n",
      "    getsizeof(...)\n",
      "        getsizeof(object [, default]) -> int\n",
      "        \n",
      "        Return the size of object in bytes.\n",
      "    \n",
      "    getswitchinterval()\n",
      "        Return the current thread switch interval; see sys.setswitchinterval().\n",
      "    \n",
      "    gettrace()\n",
      "        Return the global debug tracing function set with sys.settrace.\n",
      "        \n",
      "        See the debugger chapter in the library manual.\n",
      "    \n",
      "    intern(string, /)\n",
      "        ``Intern'' the given string.\n",
      "        \n",
      "        This enters the string in the (global) table of interned strings whose\n",
      "        purpose is to speed up dictionary lookups. Return the string itself or\n",
      "        the previously interned string object with the same value.\n",
      "    \n",
      "    is_finalizing()\n",
      "        Return True if Python is exiting.\n",
      "    \n",
      "    set_asyncgen_hooks(...)\n",
      "        set_asyncgen_hooks(* [, firstiter] [, finalizer])\n",
      "        \n",
      "        Set a finalizer for async generators objects.\n",
      "    \n",
      "    set_coroutine_origin_tracking_depth(depth)\n",
      "        Enable or disable origin tracking for coroutine objects in this thread.\n",
      "        \n",
      "        Coroutine objects will track 'depth' frames of traceback information\n",
      "        about where they came from, available in their cr_origin attribute.\n",
      "        \n",
      "        Set a depth of 0 to disable.\n",
      "    \n",
      "    setdlopenflags(flags, /)\n",
      "        Set the flags used by the interpreter for dlopen calls.\n",
      "        \n",
      "        This is used, for example, when the interpreter loads extension\n",
      "        modules. Among other things, this will enable a lazy resolving of\n",
      "        symbols when importing a module, if called as sys.setdlopenflags(0).\n",
      "        To share symbols across extension modules, call as\n",
      "        sys.setdlopenflags(os.RTLD_GLOBAL).  Symbolic names for the flag\n",
      "        modules can be found in the os module (RTLD_xxx constants, e.g.\n",
      "        os.RTLD_LAZY).\n",
      "    \n",
      "    setprofile(...)\n",
      "        setprofile(function)\n",
      "        \n",
      "        Set the profiling function.  It will be called on each function call\n",
      "        and return.  See the profiler chapter in the library manual.\n",
      "    \n",
      "    setrecursionlimit(limit, /)\n",
      "        Set the maximum depth of the Python interpreter stack to n.\n",
      "        \n",
      "        This limit prevents infinite recursion from causing an overflow of the C\n",
      "        stack and crashing Python.  The highest possible limit is platform-\n",
      "        dependent.\n",
      "    \n",
      "    setswitchinterval(interval, /)\n",
      "        Set the ideal thread switching delay inside the Python interpreter.\n",
      "        \n",
      "        The actual frequency of switching threads can be lower if the\n",
      "        interpreter executes long sequences of uninterruptible code\n",
      "        (this is implementation-specific and workload-dependent).\n",
      "        \n",
      "        The parameter must represent the desired switching delay in seconds\n",
      "        A typical value is 0.005 (5 milliseconds).\n",
      "    \n",
      "    settrace(...)\n",
      "        settrace(function)\n",
      "        \n",
      "        Set the global debug tracing function.  It will be called on each\n",
      "        function call.  See the debugger chapter in the library manual.\n",
      "    \n",
      "    unraisablehook(unraisable, /)\n",
      "        Handle an unraisable exception.\n",
      "        \n",
      "        The unraisable argument has the following attributes:\n",
      "        \n",
      "        * exc_type: Exception type.\n",
      "        * exc_value: Exception value, can be None.\n",
      "        * exc_traceback: Exception traceback, can be None.\n",
      "        * err_msg: Error message, can be None.\n",
      "        * object: Object causing the exception, can be None.\n",
      "\n",
      "DATA\n",
      "    __stderr__ = <_io.TextIOWrapper name='<stderr>' mode='w' encoding='utf...\n",
      "    __stdin__ = <_io.TextIOWrapper name='<stdin>' mode='r' encoding='utf-8...\n",
      "    __stdout__ = <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf...\n",
      "    abiflags = ''\n",
      "    api_version = 1013\n",
      "    argv = ['/data/user/0/ru.iiec.pydroid3/files/aarch64-linu...lib/python...\n",
      "    base_exec_prefix = '/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-...\n",
      "    base_prefix = '/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-andro...\n",
      "    builtin_module_names = ('_abc', '_ast', '_codecs', '_collections', '_f...\n",
      "    byteorder = 'little'\n",
      "    copyright = 'Copyright (c) 2001-2021 Python Software Foundati...ematis...\n",
      "    displayhook = <ipykernel.displayhook.ZMQShellDisplayHook object>\n",
      "    dont_write_bytecode = False\n",
      "    exec_prefix = '/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-andro...\n",
      "    executable = '/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-androi...\n",
      "    flags = sys.flags(debug=0, inspect=0, interactive=0, opt...ation=1, is...\n",
      "    float_info = sys.float_info(max=1.7976931348623157e+308, max_...epsilo...\n",
      "    float_repr_style = 'short'\n",
      "    hash_info = sys.hash_info(width=64, modulus=2305843009213693...thm='fn...\n",
      "    hexversion = 50923504\n",
      "    implementation = namespace(name='cpython', cache_tag='cpython-39'...as...\n",
      "    int_info = sys.int_info(bits_per_digit=30, sizeof_digit=4)\n",
      "    maxsize = 9223372036854775807\n",
      "    maxunicode = 1114111\n",
      "    meta_path = [<class '_frozen_importlib.BuiltinImporter'>, <class '_fro...\n",
      "    modules = {'IPython': <module 'IPython' from '/data/user/0/ru.iiec.pyd...\n",
      "    path = ['/storage/emulated/0/111py/py/joyful-pandas/notebook', '/data/...\n",
      "    path_hooks = [<class 'zipimport.zipimporter'>, <function FileFinder.pa...\n",
      "    path_importer_cache = {'/data/data/ru.iiec.pydroid3/app_HOME/.ipython/...\n",
      "    platform = 'linux'\n",
      "    platlibdir = 'lib'\n",
      "    prefix = '/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android'\n",
      "    ps1 = 'In : '\n",
      "    ps2 = '...: '\n",
      "    ps3 = 'Out: '\n",
      "    pycache_prefix = None\n",
      "    stderr = <ipykernel.iostream.OutStream object>\n",
      "    stdin = <_io.TextIOWrapper name='<stdin>' mode='r' encoding='utf-8'>\n",
      "    stdout = <ipykernel.iostream.OutStream object>\n",
      "    thread_info = sys.thread_info(name='pthread', lock='semaphore', versio...\n",
      "    version = '3.9.7 (default, Oct  6 2021, 01:34:26) \\n[GCC 11.1.0]'\n",
      "    version_info = sys.version_info(major=3, minor=9, micro=7, releaseleve...\n",
      "    warnoptions = []\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(os.path.sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 8, 27, 64, 125, 216, 343, 512, 729]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst=lambda x:[i**3 for i in range(x)]\n",
    "t=lst(10)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、文件的读取和写入\n",
    "### 1. 文件读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas`可以读取的文件格式有很多，这里主要介绍读取`csv, excel, txt`文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/my_csv.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_csv \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/my_csv.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_csv\n",
      "File \u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9/site-packages/pandas/io/parsers/readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9/site-packages/pandas/io/parsers/readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n",
      "File \u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.9/site-packages/pandas/io/common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/my_csv.csv'"
     ]
    }
   ],
   "source": [
    "df_csv = pd.read_csv('../data/my_csv.csv')\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df_csv\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#采用infex名称和列名访问指定数据块\n",
    "df.loc[1:2,'col1':'col5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nolst=['col1','col2']\n",
    "lst=df.columns\n",
    "noset=set(nolst)\n",
    "allset=set(lst)\n",
    "myset=allset-noset\n",
    "\n",
    "df[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[[('2020/1/2','b')],'col1':]\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1:2,'index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index=pd.period_range(start='2021-01',end='2021-04',freq='M')\n",
    "df['2021-02':,'col1':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getrc(df,irow,icol):\n",
    "    rows=df.shape[0]\n",
    "    cols=df.shape[1]\n",
    "    if(irow>(rows-1) or icol>(cols-1) ):\n",
    "        print(\"array over range.\")\n",
    "    else:\n",
    "        t=df.columns\n",
    "        colname=t[icol]\n",
    "        return df.loc[irow,colname]\n",
    "def modrc(df,irow,icol,val):\n",
    "    rows=df.shape[0]\n",
    "    cols=df.shape[1]\n",
    "    if(irow>(rows-1) or icol>(cols-1) ):\n",
    "        print(\"array over range.\")\n",
    "    else:\n",
    "        t=df.columns\n",
    "        colname=t[icol]\n",
    "        df.loc[irow,colname]=val\n",
    "    \n",
    "    \n",
    "m=getrc(df,1,2)\n",
    "m\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modrc(df,1,2,'gh')\n",
    "m=getrc(df,1,2)\n",
    "m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_index建立索引\n",
    "df.set_index('col3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('col1',drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.RangeIndex(1,100,2)\n",
    "# RangeIndex(start=1, stop=100, step=2)\n",
    "pd.Int64Index([1,2,3,-4], name='num')\n",
    "# Int64Index([1, 2, 3, -4], dtype='int64', name='num')\n",
    "pd.UInt64Index([1,2,3,4])\n",
    "# UInt64Index([1, 2, 3, 4], dtype='uint64')\n",
    "pd.Float64Index([1.2,2.3,3,4])\n",
    "# Float64Index([1.2, 2.3, 3.0, 4.0], dtype='float64')\n",
    "pd.CategoricalIndex(['a', 'b', 'a', 'b'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.CategoricalIndex(['a', 'b', 'a', 'b'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Index([1, 2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Index(list('abc'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Index(['e', 'd', 'a', 'b'], name='something')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('col3',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name # 名称\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.array\n",
    "df.index.dtype # 数据类型\n",
    "df.index.shape # 形状\n",
    "df.index.size # 元素数量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt = pd.read_table('../data/my_table.txt')\n",
    "df_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel('../data/my_excel.xlsx')\n",
    "df_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有一些常用的公共参数，`header=None`表示第一行不作为列名，`index_col`表示把某一列或几列作为索引，索引的内容将会在第三章进行详述，`usecols`表示读取列的集合，默认读取所有的列，`parse_dates`表示需要转化为时间的列，关于时间序列的有关内容将在第十章讲解，`nrows`表示读取的数据行数。上面这些参数在上述的三个函数里都可以使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('../data/my_table.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/my_csv.csv', index_col=['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('../data/my_table.txt', usecols=['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/my_csv.csv', parse_dates=['col5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('../data/my_excel.xlsx', nrows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在读取`txt`文件时，经常遇到分隔符非空格的情况，`read_table`有一个分割参数`sep`，它使得用户可以自定义分割符号，进行`txt`数据的读取。例如，下面的读取的表以`||||`为分割："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('../data/my_table_special_sep.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的结果显然不是理想的，这时可以使用`sep`，同时需要指定引擎为`python`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('../data/my_table_special_sep.txt', sep=' \\|\\|\\|\\| ', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【WARNING】`sep`是正则参数\n",
    "\n",
    "在使用`read_table`的时候需要注意，参数`sep`中使用的是正则表达式，因此需要对`|`进行转义变成`\\|`，否则无法读取到正确的结果。有关正则表达式的基本内容可以参考第八章或者其他相关资料。\n",
    "\n",
    "#### 【END】\n",
    "\n",
    "### 2. 数据写入\n",
    "\n",
    "一般在数据写入中，最常用的操作是把`index`设置为`False`，特别当索引没有特殊意义的时候，这样的行为能把索引在保存的时候去除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.to_csv('../data/my_csv_saved.csv', index=False)\n",
    "df_excel.to_excel('../data/my_excel_saved.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas`中没有定义`to_table`函数，但是`to_csv`可以保存为`txt`文件，并且允许自定义分隔符，常用制表符`\\t`分割："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt.to_csv('../data/my_txt_saved.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要把表格快速转换为`markdown`和`latex`语言，可以使用`to_markdown`和`to_latex`函数，此处需要安装`tabulate`包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_csv.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_csv.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、基本数据结构\n",
    "`pandas`中具有两种基本的数据存储结构，存储一维`values`的`Series`和存储二维`values`的`DataFrame`，在这两种结构上定义了很多的属性和方法。\n",
    "\n",
    "### 1. Series\n",
    "`Series`一般由四个部分组成，分别是序列的值`data`、索引`index`、存储类型`dtype`、序列的名字`name`。其中，索引也可以指定它的名字，默认为空。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(data = [100, 'a', {'dic1':5}],\n",
    "              index = pd.Index(['id1', 20, 'third'], name='my_idx'),\n",
    "              dtype = 'object',\n",
    "              name = 'my_name')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【NOTE】`object`类型\n",
    "\n",
    "`object`代表了一种混合类型，正如上面的例子中存储了整数、字符串以及`Python`的字典数据结构。此外，目前`pandas`把纯字符串序列也默认认为是一种`object`类型的序列，但它也可以用`string`类型存储，文本序列的内容会在第八章中讨论。\n",
    "\n",
    "#### 【END】\n",
    "\n",
    "对于这些属性，可以通过 . 的方式来获取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用`.shape`可以获取序列的长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引是`pandas`中最重要的概念之一，它将在第三章中被详细地讨论。如果想要取出单个索引对应的值，可以通过`[index_item]`可以取出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DataFrame\n",
    "`DataFrame`在`Series`的基础上增加了列索引，一个数据框可以由二维的`data`与行列索引来构造："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 'a', 1.2], [2, 'b', 2.2], [3, 'c', 3.2]]\n",
    "df = pd.DataFrame(data = data,\n",
    "                  index = ['row_%d'%i for i in range(3)],\n",
    "                  columns=['col_0', 'col_1', 'col_2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但一般而言，更多的时候会采用从列索引名到数据的映射来构造数据框，同时再加上行索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {'col_0': [1,2,3],\n",
    "                          'col_1':list('abc'),\n",
    "                          'col_2': [1.2, 2.2, 3.2]},\n",
    "                  index = ['row_%d'%i for i in range(3)])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于这种映射关系，在`DataFrame`中可以用`[col_name]`与`[col_list]`来取出相应的列与由多个列组成的表，结果分别为`Series`和`DataFrame`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['col_0', 'col_1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与`Series`类似，在数据框中同样可以取出相应的属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes # 返回的是值为相应列数据类型的Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过`.T`可以把`DataFrame`进行转置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、常用基本函数\n",
    "为了进行举例说明，在接下来的部分和其余章节都将会使用一份`learn_pandas.csv`的虚拟数据集，它记录了四所学校学生的体测个人信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/learn_pandas.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述列名依次代表学校、年级、姓名、性别、身高、体重、是否为转系生、体测场次、测试时间、1000米成绩，本章只需使用其中的前七列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[:7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 汇总函数\n",
    "`head, tail`函数分别表示返回表或者序列的前`n`行和后`n`行，其中`n`默认为5："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`info, describe`分别返回表的信息概况和表中数值列对应的主要统计量 ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【NOTE】更全面的数据汇总\n",
    "\n",
    "`info, describe`只能实现较少信息的展示，如果想要对一份数据集进行全面且有效的观察，特别是在列较多的情况下，推荐使用[pandas-profiling](https://pandas-profiling.github.io/pandas-profiling/docs/)包，它将在第十一章被再次提到。\n",
    "\n",
    "#### 【END】\n",
    "\n",
    "### 2. 特征统计函数\n",
    "在`Series`和`DataFrame`上定义了许多统计函数，最常见的是`sum, mean, median, var, std, max, min`。例如，选出身高和体重列进行演示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df[['Height', 'Weight']]\n",
    "df_demo.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，需要介绍的是`quantile, count, idxmax`这三个函数，它们分别返回的是分位数、非缺失值个数、最大值对应的索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.idxmax() # idxmin是对应的函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这些所有的函数，由于操作后返回的是标量，所以又称为聚合函数，它们有一个公共参数`axis`，默认为0代表逐列聚合，如果设置为1则表示逐行聚合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.mean(axis=1).head() # 在这个数据集上体重和身高的均值并没有意义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 唯一值函数\n",
    "对序列使用`unique`和`nunique`可以分别得到其唯一值组成的列表和唯一值的个数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['School'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['School'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`value_counts`可以得到唯一值和其对应出现的频数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['School'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要观察多个列组合的唯一值，可以使用`drop_duplicates`。其中的关键参数是`keep`，默认值`first`表示每个组合保留第一次出现的所在行，`last`表示保留最后一次出现的所在行，`False`表示把所有重复组合所在的行剔除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df[['Gender','Transfer','Name']]\n",
    "df_demo.drop_duplicates(['Gender', 'Transfer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.drop_duplicates(['Gender', 'Transfer'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.drop_duplicates(['Name', 'Gender'], keep=False).head() # 保留只出现过一次的性别和姓名组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['School'].drop_duplicates() # 在Series上也可以使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，`duplicated`和`drop_duplicates`的功能类似，但前者返回了是否为唯一值的布尔列表，其`keep`参数与后者一致。其返回的序列，把重复元素设为`True`，否则为`False`。 `drop_duplicates`等价于把`duplicated`为`True`的对应行剔除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.duplicated(['Gender', 'Transfer']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['School'].duplicated().head() # 在Series上也可以使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 替换函数\n",
    "一般而言，替换操作是针对某一个列进行的，因此下面的例子都以`Series`举例。`pandas`中的替换函数可以归纳为三类：映射替换、逻辑替换、数值替换。其中映射替换包含`replace`方法、第八章中的`str.replace`方法以及第九章中的`cat.codes`方法，此处介绍`replace`的用法。\n",
    "\n",
    "在`replace`中，可以通过字典构造，或者传入两个列表来进行替换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace({'Female':0, 'Male':1}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace(['Female', 'Male'], [0, 1]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，`replace`还有一种特殊的方向替换，指定`method`参数为`ffill`则为用前面一个最近的未被替换的值进行替换，`bfill`则使用后面最近的未被替换的值进行替换。从下面的例子可以看到，它们的结果是不同的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['a', 1, 'b', 2, 1, 1, 'a'])\n",
    "s.replace([1, 2], method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.replace([1, 2], method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【WARNING】正则替换请使用`str.replace`\n",
    "\n",
    "虽然对于`replace`而言可以使用正则替换，但是当前版本下对于`string`类型的正则替换还存在`bug`，因此如有此需求，请选择`str.replace`进行替换操作，具体的方式将在第八章中讲解。\n",
    "\n",
    "#### 【END】\n",
    "\n",
    "逻辑替换包括了`where`和`mask`，这两个函数是完全对称的：`where`函数在传入条件为`False`的对应行进行替换，而`mask`在传入条件为`True`的对应行进行替换，当不指定替换值时，替换为缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([-1, 1.2345, 100, -50])\n",
    "s.where(s<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.where(s<0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.mask(s<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.mask(s<0, -50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，传入的条件只需是与被调用的`Series`索引一致的布尔序列即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_condition= pd.Series([True,False,False,True],index=s.index)\n",
    "s.mask(s_condition, -50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数值替换包含了`round, abs, clip`方法，它们分别表示按照给定精度四舍五入、取绝对值和截断："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([-1, 1.2345, 100, -50])\n",
    "s.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.clip(0, 2) # 前两个数分别表示上下截断边界"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【练一练】\n",
    "\n",
    "在 clip 中，超过边界的只能截断为边界值，如果要把超出边界的替换为自定义的值，应当如何做？\n",
    "\n",
    "#### 【END】\n",
    "\n",
    "### 5. 排序函数\n",
    "排序共有两种方式，其一为值排序，其二为索引排序，对应的函数是`sort_values`和`sort_index`。\n",
    "\n",
    "为了演示排序函数，下面先利用`set_index`方法把年级和姓名两列作为索引，多级索引的内容和索引设置的方法将在第三章进行详细讲解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df[['Grade', 'Name', 'Height', 'Weight']].set_index(['Grade','Name'])\n",
    "df_demo.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对身高进行排序，默认参数`ascending=True`为升序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.sort_values('Height').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.sort_values('Height', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在排序中，经常遇到多列排序的问题，比如在体重相同的情况下，对身高进行排序，并且保持身高降序排列，体重升序排列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.sort_values(['Weight','Height'],ascending=[True,False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引排序的用法和值排序完全一致，只不过元素的值在索引中，此时需要指定索引层的名字或者层号，用参数`level`表示。另外，需要注意的是字符串的排列顺序由字母顺序决定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.sort_index(level=['Grade','Name'],ascending=[True,False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. apply方法\n",
    "`apply`方法常用于`DataFrame`的行迭代或者列迭代，它的`axis`含义与第2小节中的统计聚合函数一致，`apply`的参数往往是一个以序列为输入的函数。例如对于`.mean()`，使用`apply`可以如下地写出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df[['Height', 'Weight']]\n",
    "def my_mean(x):\n",
    "     res = x.mean()\n",
    "     return res\n",
    "df_demo.apply(my_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样的，可以利用`lambda`表达式使得书写简洁，这里的`x`就指代被调用的`df_demo`表中逐个输入的序列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.apply(lambda x:x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若指定`axis=1`，那么每次传入函数的就是行元素组成的`Series`，其结果与之前的逐行均值结果一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.apply(lambda x:x.mean(), axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里再举一个例子：`mad`函数返回的是一个序列中偏离该序列均值的绝对值大小的均值，例如序列1,3,7,10中，均值为5.25，每一个元素偏离的绝对值为4.25,2.25,1.75,4.75，这个偏离序列的均值为3.25。现在利用`apply`计算升高和体重的`mad`指标："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.apply(lambda x:(x-x.mean()).abs().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这与使用内置的`mad`函数计算结果一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.mad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【WARNING】谨慎使用`apply`\n",
    "\n",
    "得益于传入自定义函数的处理，`apply`的自由度很高，但这是以性能为代价的。一般而言，使用`pandas`的内置函数处理和`apply`来处理同一个任务，其速度会相差较多，因此只有在确实存在自定义需求的情境下才考虑使用`apply`。\n",
    "\n",
    "#### 【END】\n",
    "\n",
    "## 四、窗口对象\n",
    "`pandas`中有3类窗口，分别是滑动窗口`rolling`、扩张窗口`expanding`以及指数加权窗口`ewm`。需要说明的是，以日期偏置为窗口大小的滑动窗口将在第十章讨论，指数加权窗口见本章练习。\n",
    "\n",
    "### 1. 滑窗对象\n",
    "要使用滑窗函数，就必须先要对一个序列使用`.rolling`得到滑窗对象，其最重要的参数为窗口大小`window`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,4,5])\n",
    "roller = s.rolling(window = 3)\n",
    "roller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在得到了滑窗对象后，能够使用相应的聚合函数进行计算，需要注意的是窗口包含当前行所在的元素，例如在第四个位置进行均值运算时，应当计算(2+3+4)/3，而不是(1+2+3)/3："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roller.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roller.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于滑动相关系数或滑动协方差的计算，可以如下写出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.Series([1,2,6,16,30])\n",
    "roller.cov(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roller.corr(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，还支持使用`apply`传入自定义函数，其传入值是对应窗口的`Series`，例如上述的均值函数可以等效表示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roller.apply(lambda x:x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shift, diff, pct_change`是一组类滑窗函数，它们的公共参数为`periods=n`，默认为1，分别表示取向前第`n`个元素的值、与向前第`n`个元素做差（与`Numpy`中不同，后者表示`n`阶差分）、与向前第`n`个元素相比计算增长率。这里的`n`可以为负，表示反方向的类似操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,3,6,10,15])\n",
    "s.shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.diff(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.diff(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将其视作类滑窗函数的原因是，它们的功能可以用窗口大小为`n+1`的`rolling`方法等价代替："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.rolling(3).apply(lambda x:list(x)[0]) # s.shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " s.rolling(4).apply(lambda x:list(x)[-1]-list(x)[0]) # s.diff(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pct(x):\n",
    "     L = list(x)\n",
    "     return L[-1]/L[0]-1\n",
    "s.rolling(2).apply(my_pct) # s.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【练一练】\n",
    "\n",
    "`rolling`对象的默认窗口方向都是向前的，某些情况下用户需要向后的窗口，例如对1,2,3设定向后窗口为2的`sum`操作，结果为3,5,NaN，此时应该如何实现向后的滑窗操作？\n",
    "\n",
    "#### 【END】\n",
    "\n",
    "### 2. 扩张窗口\n",
    "扩张窗口又称累计窗口，可以理解为一个动态长度的窗口，其窗口的大小就是从序列开始处到具体操作的对应位置，其使用的聚合函数会作用于这些逐步扩张的窗口上。具体地说，设序列为a1, a2, a3, a4，则其每个位置对应的窗口即\\[a1\\]、\\[a1, a2\\]、\\[a1, a2, a3\\]、\\[a1, a2, a3, a4\\]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 6, 10])\n",
    "s.expanding().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【练一练】\n",
    "\n",
    "`cummax, cumsum, cumprod`函数是典型的类扩张窗口函数，请使用`expanding`对象依次实现它们。\n",
    "\n",
    "#### 【END】\n",
    "\n",
    "## 五、练习\n",
    "### Ex1：口袋妖怪数据集\n",
    "现有一份口袋妖怪的数据集，下面进行一些背景说明：\n",
    "\n",
    "* `#`代表全国图鉴编号，不同行存在相同数字则表示为该妖怪的不同状态\n",
    "\n",
    "* 妖怪具有单属性和双属性两种，对于单属性的妖怪，`Type 2`为缺失值\n",
    "* `Total, HP, Attack, Defense, Sp. Atk, Sp. Def, Speed`分别代表种族值、体力、物攻、防御、特攻、特防、速度，其中种族值为后6项之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/pokemon.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对`HP, Attack, Defense, Sp. Atk, Sp. Def, Speed`进行加总，验证是否为`Total`值。\n",
    "\n",
    "2. 对于`#`重复的妖怪只保留第一条记录，解决以下问题：\n",
    "\n",
    "* 求第一属性的种类数量和前三多数量对应的种类\n",
    "* 求第一属性和第二属性的组合种类\n",
    "* 求尚未出现过的属性组合\n",
    "\n",
    "3. 按照下述要求，构造`Series`：\n",
    "\n",
    "* 取出物攻，超过120的替换为`high`，不足50的替换为`low`，否则设为`mid`\n",
    "* 取出第一属性，分别用`replace`和`apply`替换所有字母为大写\n",
    "* 求每个妖怪六项能力的离差，即所有能力中偏离中位数最大的值，添加到`df`并从大到小排序\n",
    "\n",
    "### Ex2：指数加权窗口\n",
    "1. 作为扩张窗口的`ewm`窗口\n",
    "\n",
    "在扩张窗口中，用户可以使用各类函数进行历史的累计指标统计，但这些内置的统计函数往往把窗口中的所有元素赋予了同样的权重。事实上，可以给出不同的权重来赋给窗口中的元素，指数加权窗口就是这样一种特殊的扩张窗口。\n",
    "\n",
    "其中，最重要的参数是`alpha`，它决定了默认情况下的窗口权重为$w_i=(1−\\alpha)^i,i\\in\\{0,1,...,t\\}$，其中$i=t$表示当前元素，$i=0$表示序列的第一个元素。\n",
    "\n",
    "从权重公式可以看出，离开当前值越远则权重越小，若记原序列为$x$，更新后的当前元素为$y_t$，此时通过加权公式归一化后可知：\n",
    "\n",
    "$$\n",
    "\\begin{split}y_t &=\\frac{\\sum_{i=0}^{t} w_i x_{t-i}}{\\sum_{i=0}^{t} w_i} \\\\\n",
    "&=\\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ...\n",
    "+ (1 - \\alpha)^{t} x_{0}}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ...\n",
    "+ (1 - \\alpha)^{t}}\\\\\\end{split}\n",
    "$$\n",
    "\n",
    "对于`Series`而言，可以用`ewm`对象如下计算指数平滑后的序列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "s = pd.Series(np.random.randint(-1,2,30).cumsum())\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.ewm(alpha=0.2).mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请用`expanding`窗口实现。\n",
    "\n",
    "2. 作为滑动窗口的`ewm`窗口\n",
    "\n",
    "从第1问中可以看到，`ewm`作为一种扩张窗口的特例，只能从序列的第一个元素开始加权。现在希望给定一个限制窗口`n`，只对包含自身的最近的`n`个元素作为窗口进行滑动加权平滑。请根据滑窗函数，给出新的`wi`与`yt`的更新公式，并通过`rolling`窗口实现这一功能。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
